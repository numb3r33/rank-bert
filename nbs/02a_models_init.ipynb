{"cells":[{"cell_type":"markdown","metadata":{"id":"xr2oeBb7yKwE"},"source":["# Model Initialization\n","\n","> Utilities for initializing and configuring models for rank manipulation experiments"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"GpsVLFI-yKwF","executionInfo":{"status":"ok","timestamp":1742276741833,"user_tz":-330,"elapsed":13,"user":{"displayName":"Abhishek Sharma","userId":"11883431818886671775"}}},"outputs":[],"source":["#| default_exp models.init_utils"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ulM03rO6yKwF","executionInfo":{"status":"ok","timestamp":1742276763275,"user_tz":-330,"elapsed":20691,"user":{"displayName":"Abhishek Sharma","userId":"11883431818886671775"}},"outputId":"3e37dc7c-1544-4c03-dbee-e0f1c7c45092"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/rank-bert\n"]}],"source":["#| hide\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    %cd /content/drive/MyDrive/rank-bert\n","except:\n","    pass"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OPrpGe5ayKwF","executionInfo":{"status":"ok","timestamp":1742276776290,"user_tz":-330,"elapsed":10773,"user":{"displayName":"Abhishek Sharma","userId":"11883431818886671775"}},"outputId":"82cfa042-4946-4491-968d-d12ccc50c1b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["#| hide\n","try:\n","    !pip install -q nbdev\n","except:\n","    pass"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"CokY51f7yKwG","executionInfo":{"status":"ok","timestamp":1742276778865,"user_tz":-330,"elapsed":851,"user":{"displayName":"Abhishek Sharma","userId":"11883431818886671775"}}},"outputs":[],"source":["#| hide\n","from nbdev.showdoc import *"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"wcCgjhf9yKwG","executionInfo":{"status":"ok","timestamp":1742277169042,"user_tz":-330,"elapsed":39,"user":{"displayName":"Abhishek Sharma","userId":"11883431818886671775"}}},"outputs":[],"source":["#| export\n","import torch\n","import torch.nn as nn\n","import math\n","import numpy as np\n","from copy import deepcopy\n","from typing import Dict, List, Optional, Tuple, Union\n","\n","from fastai.text.all import *\n","from transformers import (\n","    AutoConfig,\n","    AutoModelForSequenceClassification,\n","    BertConfig,\n","    BertForSequenceClassification,\n","    BertModel\n",")\n","\n","from rank_bert.models.base_models import (\n","    get_pretrained_model,\n","    BertWrapper,\n","    count_parameters,\n","    BERT_CONFIGS,\n","    GLUE_NUM_LABELS\n",")"]},{"cell_type":"markdown","metadata":{"id":"QEy0UctPyKwG"},"source":["## Advanced Model Initialization Utilities\n","\n","This module provides advanced utilities for initializing and configuring BERT models for rank manipulation experiments. These utilities extend the basic model creation functions from the base_models module."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Xj3dpUvpyKwG","executionInfo":{"status":"ok","timestamp":1742276831311,"user_tz":-330,"elapsed":40,"user":{"displayName":"Abhishek Sharma","userId":"11883431818886671775"}}},"outputs":[],"source":["#| export\n","def create_model_from_config(config: Union[Dict, BertConfig], model_class=BertForSequenceClassification):\n","    \"\"\"\n","    Create a model from a configuration dictionary or BertConfig object.\n","\n","    Args:\n","        config (Dict or BertConfig): Configuration for the model\n","        model_class: The model class to instantiate (default: BertForSequenceClassification)\n","\n","    Returns:\n","        The instantiated model\n","    \"\"\"\n","    if isinstance(config, dict):\n","        config = BertConfig(**config)\n","\n","    return model_class(config)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"2XRfpGWFyKwG","executionInfo":{"status":"ok","timestamp":1742276832973,"user_tz":-330,"elapsed":9,"user":{"displayName":"Abhishek Sharma","userId":"11883431818886671775"}}},"outputs":[],"source":["#| export\n","def get_model_config(model_name: str, task_name: str, num_labels: Optional[int] = None) -> BertConfig:\n","    \"\"\"\n","    Get a configuration object for a model.\n","\n","    Args:\n","        model_name (str): HuggingFace model name or path (e.g., 'prajjwal1/bert-tiny')\n","        task_name (str): GLUE task name ('sst2', 'mrpc', 'rte')\n","        num_labels (int, optional): Number of output labels\n","\n","    Returns:\n","        BertConfig: Configuration object for the model\n","    \"\"\"\n","    # Get the number of labels for the task\n","    num_labels = num_labels or GLUE_NUM_LABELS.get(task_name, 2)\n","\n","    # Check if the model name is a known configuration or a HuggingFace model\n","    if model_name in BERT_CONFIGS:\n","        # Create a new configuration with the specified parameters\n","        config = BertConfig(\n","            **BERT_CONFIGS[model_name],\n","            num_labels=num_labels,\n","            hidden_dropout_prob=0.1,\n","            attention_probs_dropout_prob=0.1\n","        )\n","    else:\n","        # Load a pretrained configuration from HuggingFace\n","        config = AutoConfig.from_pretrained(model_name, num_labels=num_labels)\n","\n","    return config"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"4VFYBuuDyKwH","executionInfo":{"status":"ok","timestamp":1742277176479,"user_tz":-330,"elapsed":8,"user":{"displayName":"Abhishek Sharma","userId":"11883431818886671775"}}},"outputs":[],"source":["#| export\n","def modify_config_for_rank_experiments(config: BertConfig, hidden_size: Optional[int] = None,\n","                                      num_hidden_layers: Optional[int] = None,\n","                                      num_attention_heads: Optional[int] = None,\n","                                      intermediate_size: Optional[int] = None) -> BertConfig:\n","    \"\"\"\n","    Modify a configuration for rank manipulation experiments.\n","\n","    Args:\n","        config (BertConfig): Original configuration\n","        hidden_size (int, optional): Hidden size for the model\n","        num_hidden_layers (int, optional): Number of hidden layers\n","        num_attention_heads (int, optional): Number of attention heads\n","        intermediate_size (int, optional): Intermediate size for feed-forward networks\n","\n","    Returns:\n","        BertConfig: Modified configuration\n","    \"\"\"\n","    # Create a copy of the config to avoid modifying the original\n","    new_config = deepcopy(config)\n","\n","    # Update configuration parameters if provided\n","    if hidden_size is not None:\n","        new_config.hidden_size = hidden_size\n","\n","    if num_hidden_layers is not None:\n","        new_config.num_hidden_layers = num_hidden_layers\n","\n","    if num_attention_heads is not None:\n","        new_config.num_attention_heads = num_attention_heads\n","\n","    if intermediate_size is not None:\n","        new_config.intermediate_size = intermediate_size\n","\n","    return new_config"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"qXg2KNY7yKwH","executionInfo":{"status":"ok","timestamp":1742277178108,"user_tz":-330,"elapsed":9,"user":{"displayName":"Abhishek Sharma","userId":"11883431818886671775"}}},"outputs":[],"source":["#| export\n","def initialize_weights(model: nn.Module, method: str = 'normal', **kwargs):\n","    \"\"\"\n","    Initialize weights of a model using the specified method.\n","\n","    Args:\n","        model (nn.Module): PyTorch model\n","        method (str): Initialization method ('normal', 'xavier', 'kaiming', 'orthogonal')\n","        **kwargs: Additional arguments for the initialization method\n","\n","    Returns:\n","        nn.Module: Model with initialized weights\n","    \"\"\"\n","    def _init_weights(module):\n","        if isinstance(module, (nn.Linear, nn.Embedding)):\n","            # Initialize weights based on the specified method\n","            if method == 'normal':\n","                std = kwargs.get('std', 0.02)\n","                nn.init.normal_(module.weight, mean=0.0, std=std)\n","            elif method == 'xavier':\n","                gain = kwargs.get('gain', 1.0)\n","                nn.init.xavier_normal_(module.weight, gain=gain)\n","            elif method == 'kaiming':\n","                a = kwargs.get('a', 0)\n","                mode = kwargs.get('mode', 'fan_in')\n","                nonlinearity = kwargs.get('nonlinearity', 'relu')\n","                nn.init.kaiming_normal_(module.weight, a=a, mode=mode, nonlinearity=nonlinearity)\n","            elif method == 'orthogonal':\n","                gain = kwargs.get('gain', 1.0)\n","                nn.init.orthogonal_(module.weight, gain=gain)\n","            else:\n","                raise ValueError(f\"Unsupported initialization method: {method}\")\n","\n","            # Initialize bias if it exists\n","            if hasattr(module, 'bias') and module.bias is not None:\n","                nn.init.zeros_(module.bias)\n","\n","        elif isinstance(module, nn.LayerNorm):\n","            # LayerNorm layers are initialized with ones and zeros\n","            nn.init.ones_(module.weight)\n","            nn.init.zeros_(module.bias)\n","\n","    # Apply initialization to all submodules\n","    model.apply(_init_weights)\n","\n","    return model"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"0bwAFQeSyKwH","executionInfo":{"status":"ok","timestamp":1742277181168,"user_tz":-330,"elapsed":5,"user":{"displayName":"Abhishek Sharma","userId":"11883431818886671775"}}},"outputs":[],"source":["#| export\n","def default_transformer_splitter(model):\n","    \"\"\"\n","    Default parameter group splitter for transformer models.\n","    Separates parameters into layer-wise groups for differential learning rates.\n","\n","    Args:\n","        model: Transformer model\n","\n","    Returns:\n","        List of parameter groups\n","    \"\"\"\n","    # Get the actual model if it's wrapped\n","    if hasattr(model, 'model'):\n","        model = model.model\n","\n","    # Extract layers from the model\n","    embeddings = [p for n, p in model.named_parameters() if 'embeddings' in n]\n","    encoder_layers = []\n","\n","    # Check if the model has a bert attribute (BertForSequenceClassification)\n","    if hasattr(model, 'bert'):\n","        num_layers = model.bert.config.num_hidden_layers\n","        # Collect parameters for each encoder layer\n","        for i in range(num_layers):\n","            encoder_layers.append([p for n, p in model.named_parameters()\n","                                  if f'encoder.layer.{i}.' in n])\n","    # Handle base BERT model\n","    elif hasattr(model, 'encoder'):\n","        num_layers = model.config.num_hidden_layers\n","        # Collect parameters for each encoder layer\n","        for i in range(num_layers):\n","            encoder_layers.append([p for n, p in model.named_parameters()\n","                                  if f'encoder.layer.{i}.' in n])\n","\n","    # Extract classifier parameters\n","    classifier = [p for n, p in model.named_parameters() if 'classifier' in n or 'pooler' in n]\n","\n","    # Construct parameter groups, reverting order for discriminative learning rates\n","    # (later layers with higher learning rates)\n","    param_groups = encoder_layers + [classifier, embeddings]\n","    param_groups.reverse()\n","\n","    return param_groups"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"xnccVrq0yKwH","executionInfo":{"status":"ok","timestamp":1742277182228,"user_tz":-330,"elapsed":2,"user":{"displayName":"Abhishek Sharma","userId":"11883431818886671775"}}},"outputs":[],"source":["#| export\n","class TransformerCallback(Callback):\n","    \"\"\"\n","    Callback for handling transformer-specific training operations.\n","    Manages input/output format conversion between fastai and transformers.\n","    \"\"\"\n","\n","    def __init__(self):\n","        self.tokenizer = None\n","\n","    def before_batch(self):\n","        \"Ensure inputs are in the expected format for transformers\"\n","        # fastai might pack the inputs from the data loader\n","        if isinstance(self.learn.xb, tuple) and len(self.learn.xb) == 1:\n","            self.learn.xb = self.learn.xb[0]\n","\n","    def after_pred(self):\n","        \"Process outputs from the model\"\n","        # If the model returns a tuple or list (common for transformers), handle it\n","        if isinstance(self.learn.pred, tuple) or isinstance(self.learn.pred, list):\n","            self.learn.pred = self.learn.pred[0]  # Usually logits are the first element"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"8yADUJDWyKwH","executionInfo":{"status":"ok","timestamp":1742277183570,"user_tz":-330,"elapsed":10,"user":{"displayName":"Abhishek Sharma","userId":"11883431818886671775"}}},"outputs":[],"source":["#| export\n","def create_model_with_config(config_or_model_name, task_name=None, num_labels=None, **kwargs):\n","    \"\"\"\n","    Create a model using either a configuration object or model name.\n","\n","    Args:\n","        config_or_model_name: Either a BertConfig object or a model name string\n","        task_name (str, optional): GLUE task name (required if config_or_model_name is a string)\n","        num_labels (int, optional): Number of output labels\n","        **kwargs: Additional arguments to modify the configuration\n","\n","    Returns:\n","        The instantiated model\n","    \"\"\"\n","    if isinstance(config_or_model_name, (BertConfig, dict)):\n","        config = config_or_model_name\n","        if isinstance(config, dict):\n","            if num_labels is not None:\n","                config['num_labels'] = num_labels\n","            config = BertConfig(**config)\n","        elif num_labels is not None:\n","            config.num_labels = num_labels\n","    else:\n","        # Assume config_or_model_name is a model name string\n","        if task_name is None:\n","            raise ValueError(\"task_name must be provided when config_or_model_name is a model name string\")\n","        config = get_model_config(config_or_model_name, task_name, num_labels)\n","\n","    # Apply configuration modifications\n","    if kwargs:\n","        config = modify_config_for_rank_experiments(config, **kwargs)\n","\n","    return create_model_from_config(config)"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"ngC-A75dyKwH","executionInfo":{"status":"ok","timestamp":1742277184754,"user_tz":-330,"elapsed":10,"user":{"displayName":"Abhishek Sharma","userId":"11883431818886671775"}}},"outputs":[],"source":["#| export\n","def get_custom_bert_model(model_type, task_name, num_labels=None):\n","    \"\"\"\n","    Get a customized BERT model for rank experiments.\n","\n","    Args:\n","        model_type (str): Type of BERT model ('tiny', 'mini', 'small', 'custom')\n","        task_name (str): GLUE task name\n","        num_labels (int, optional): Number of output labels\n","\n","    Returns:\n","        The instantiated model\n","    \"\"\"\n","    # Map model type to HuggingFace model name\n","    model_mapping = {\n","        'tiny': 'prajjwal1/bert-tiny',\n","        'mini': 'prajjwal1/bert-mini',\n","        'small': 'prajjwal1/bert-small'\n","    }\n","\n","    if model_type in model_mapping:\n","        return get_pretrained_model(model_mapping[model_type], task_name, num_labels)\n","    elif model_type == 'custom':\n","        # Create a fully custom BERT model with specified parameters\n","        config = BertConfig(\n","            vocab_size=30522,  # Default BERT vocab size\n","            hidden_size=256,\n","            num_hidden_layers=4,\n","            num_attention_heads=4,\n","            intermediate_size=1024,\n","            hidden_dropout_prob=0.1,\n","            attention_probs_dropout_prob=0.1,\n","            max_position_embeddings=512,\n","            type_vocab_size=2,\n","            initializer_range=0.02,\n","            layer_norm_eps=1e-12,\n","            num_labels=num_labels or GLUE_NUM_LABELS.get(task_name, 2)\n","        )\n","        return BertForSequenceClassification(config)\n","    else:\n","        raise ValueError(f\"Unknown model type: {model_type}. Use 'tiny', 'mini', 'small', or 'custom'\")"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"Psnr1atWyKwI","executionInfo":{"status":"ok","timestamp":1742277185841,"user_tz":-330,"elapsed":1,"user":{"displayName":"Abhishek Sharma","userId":"11883431818886671775"}}},"outputs":[],"source":["#| export\n","def optimize_model_for_training(model, device=None, mixed_precision=False):\n","    \"\"\"\n","    Optimize a model for efficient training.\n","\n","    Args:\n","        model: PyTorch model\n","        device: Device to move the model to (default: detect automatically)\n","        mixed_precision: Whether to use mixed precision training\n","\n","    Returns:\n","        Optimized model\n","    \"\"\"\n","    # Determine device if not provided\n","    if device is None:\n","        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    # Move model to appropriate device\n","    model = model.to(device)\n","\n","    # Apply mixed precision if requested and on GPU\n","    if mixed_precision and device.type == 'cuda':\n","        try:\n","            from torch.cuda.amp import autocast\n","            # Wrap model's forward method with autocast\n","            original_forward = model.forward\n","            model.forward = autocast()(original_forward)\n","        except ImportError:\n","            print(\"Mixed precision training not available. Falling back to full precision.\")\n","\n","    # Free unused memory\n","    if device.type == 'cuda':\n","        torch.cuda.empty_cache()\n","\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"XlyawToWyKwI"},"source":["## Examples\n","\n","Here are some examples of how to use the model initialization utilities."]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TbHaN_M_yKwI","executionInfo":{"status":"ok","timestamp":1742277187852,"user_tz":-330,"elapsed":426,"user":{"displayName":"Abhishek Sharma","userId":"11883431818886671775"}},"outputId":"29ddc96e-7d5d-43e0-db75-b9f42ed0906b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Custom model parameter count: 17,590,146\n"]}],"source":["# Example 1: Create a model with custom configuration\n","custom_config = get_model_config('prajjwal1/bert-mini', 'sst2')\n","custom_config = modify_config_for_rank_experiments(custom_config, hidden_size=384, num_attention_heads=6)\n","model = create_model_from_config(custom_config)\n","print(f\"Custom model parameter count: {count_parameters(model):,}\")"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hhP-XmdoyKwI","executionInfo":{"status":"ok","timestamp":1742277190949,"user_tz":-330,"elapsed":408,"user":{"displayName":"Abhishek Sharma","userId":"11883431818886671775"}},"outputId":"86d4b223-a4e4-46af-a8ac-2cd23efab1c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Orthogonally initialized model parameter count: 4,386,178\n"]}],"source":["# Example 2: Create a model and initialize its weights using orthogonal initialization\n","model = get_custom_bert_model('tiny', 'mrpc')\n","model = initialize_weights(model, method='orthogonal', gain=1.0)\n","print(f\"Orthogonally initialized model parameter count: {count_parameters(model):,}\")"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ll0zQ4GcyKwI","executionInfo":{"status":"ok","timestamp":1742277195016,"user_tz":-330,"elapsed":259,"user":{"displayName":"Abhishek Sharma","userId":"11883431818886671775"}},"outputId":"fa54be1d-ef88-45f6-bcfb-37f58d78cee5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Custom model parameter count: 14,310,978\n"]}],"source":["# Example 3: Use the simplified model creation function\n","model = create_model_with_config('prajjwal1/bert-mini', 'rte', hidden_size=320, num_attention_heads=5)\n","print(f\"Custom model parameter count: {count_parameters(model):,}\")"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"__Dyoha2yKwI","executionInfo":{"status":"ok","timestamp":1742277220807,"user_tz":-330,"elapsed":4207,"user":{"displayName":"Abhishek Sharma","userId":"11883431818886671775"}}},"outputs":[],"source":["#| hide\n","import nbdev; nbdev.nbdev_export()"]}],"metadata":{"kernelspec":{"display_name":"python3","language":"python","name":"python3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}